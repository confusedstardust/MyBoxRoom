# __author:XiaoHe
# data:2022/1/6
"""
这是一个爬取电影天堂的小工具
用户输入所需的第一页、最后一页、文件名
通过合法性校验后，开始收集并写入指定的路径，生成相应的xls文档
执行过程中会出现正在处理的电影名称
待mission success的字样出现后即可打开
"""
import requests
import re

import xlwt
from bs4 import BeautifulSoup

headers = {
    "User-Agent": "用自己的",
    "Cookie": "用自己的"
}
dataList = []  # 用来存爬取到的内容


# 动态获取最新电影目录中的目录页，返回html页面
def asKUrl(num):
    reqUrl = requests.get(f'https://www.dytt8.net/html/gndy/dyzz/list_23_{str(num)}.html', headers=headers)
    reqUrl.encoding = "gb2312"  # 主要看目标网站采用什么编码格式
    return reqUrl


# 接收html页面，封装成soup对象，便于操作结点
def solveUrl(reqUrl):
    bsobj = BeautifulSoup(reqUrl.text, "lxml")
    return bsobj


# 接收取得的子链接，对子链接发送请求，拿到对应链接的下载地址
def getSrcLink(link):
    # 发送请求获取资源详情页
    srcPage = requests.get(f'https://www.dytt8.net{link}', headers=headers)
    srcPage.encoding = "gb2312"
    bsobj = solveUrl(srcPage)
    # 定义一个寻找下载地址的attrs
    attrs = {
        "style": "WORD-WRAP: break-word",
        "bgcolor": "#fdfddf"
    }
    # 有两种不同的下载连接格式，选择不同方案
    # 为防止有些链接已失效，加入try catch，并在失效电影对应的表中告知错误
    try:
        if (len(bsobj.find_all("td", attrs=attrs))):
            srclink = bsobj.find_all("td", attrs=attrs)[0]
            srclink = re.findall(r'<a href="(.*?)">', str(srclink))
        else:
            srclink = re.findall(r'<a href="magnet(.*?)"', str(bsobj))[0]
            srclink = "magnet" + srclink
    except  IndexError as error:
        srclink = "此电影的页面或链接解析时出线了问题亦可能是此链接已被删除或更改"
        print("此电影的页面或链接解析时出线了问题亦可能是此链接已被删除或更改")
    finally:
        return srclink
    # 得到下载地址


# 接收首页与尾页参数
def getData(front, rear):
    # 定义每个目录页的条目属性便于选取
    attrs = {
        "border": "0",
        "cellpadding": "0",
        "width": "100%"
    }
    # 开始从首页到尾页逐个“搬家”
    for i in range(front, rear + 1):
        reqUrl = asKUrl(i)
        bsobj = solveUrl(reqUrl)
        for item in bsobj.find_all("table", attrs=attrs):
            data = []
            item = str(item)
            titleName = re.findall(r'<a class="ulink" href=".*?html">(.*?)</a>', item)[0]
            print(titleName)
            link = re.findall(r'<a class="ulink" href="(.*?)">', item)[0]
            videoSrc = getSrcLink(link)
            data.append(titleName)
            data.append(videoSrc)
            dataList.append(data)


# 做输入数据的合法性校验页数要在1-241(包括)之内
def judgeVal(front, rear):
    if (front >= 1 and rear >= front and rear < 242):
        if rear <= 240:
            total = (rear - front + 1) * 25
            return total
        elif rear == 241:
            total = (rear - front) * 25 + 4
            return total
    else:
        return print("请输入合理页数")


# 校验文件名的合法性，如果文件名出现问题，则让用户重新输入(递归实现重复判断)
def judgeFileName(savePath):
    fileNameRule = re.compile(r'^[^/\\\\:\\*\\?\\<\\>\\|\"]{1,255}$')
    if re.search(fileNameRule, savePath):
        return savePath
    else:
        savePath = input("输入合法的存储路径！！")
        judgeFileName(savePath)
        return savePath


# 保存
def saveData(dataList, savepath, total):
    book = xlwt.Workbook(encoding="utf-8")
    sheet = book.add_sheet("dyttData")
    # 定义列名
    col = ("电影名称", "下载链接")
    for i in range(0, 2):
        sheet.write(0, i, col[i])  # 写入列名
    for i in range(0, total):
        data = dataList[i]
        for j in range(0, 2):
            sheet.write(i + 1, j, data[j])
    book.save(savepath)
    print("mission.....success")


if __name__ == '__main__':
    front = input("请输入开始下载的页数：")
    rear = input("请输入停止下载的页数：")
    savePath = input("请输入文件名：")
    savePath = judgeFileName(savePath)
    front = int(front)
    rear = int(rear)
    total = judgeVal(front, rear)
    getData(front, rear)
    savePath = savePath + ".xls"
    saveData(dataList, savePath, total)
